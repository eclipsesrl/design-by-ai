---
f_source: >-
  https://www.forbes.com/sites/karlfreund/2021/04/12/nvidia-completely-re-imagines-the-data-center-for-ai
f_article-thumbnail-image-url: >-
  https://specials-images.forbesimg.com/imageserve/607475a5a82d88e6bcfe3ed8/960x0.jpg?fit=scale
title: NVIDIA Completely Re-Imagines The Data Center For AI
f_text: >-
  It is all about tighter integration with memory, CPUs, and accelerators for
  trillion-parameter AI models.
f_title: NVIDIA Completely Re-Imagines The Data Center For AI
f_image-url: >-
  https://specials-images.forbesimg.com/imageserve/607475a5a82d88e6bcfe3ed8/960x0.jpg?fit=scale
slug: nvidia-completely-re-imagines-the-data-center-for-ai
f_category-5: cms/categories/ai-ml.md
updated-on: '2021-11-25T13:10:57.295Z'
created-on: '2021-04-26T09:12:28.029Z'
published-on: '2022-03-03T08:54:19.378Z'
f_featured: false
f_trending: false
f_tags:
  - cms/tags/gpt3.md
layout: '[posts].html'
tags: posts
---

> "...the goal is to create a tightly integrated computational foundation to pursue the next wave of AI innovation: a trillion-parameter computer intelligence. Today's largest AI model is the Open.ai GPT-3, totaling 170 billion parameters for language processing, requiring over one thousand NVIDIA GPUs hosted by Microsoft Azure. The human brain has about 100 trillion synapses, roughly equivalent to the deep neural network parameters. If successful, the NVIDIA system would be only 100 times slower than the human brain."
