---
title: More Compute Power Doesn’t Produce Artificial General Intelligence
created-on: 2021-11-14T23:04:27.153Z
updated-on: 2021-11-25T12:58:06.622Z
published-on: 2022-03-03T08:54:19.378Z
f_article-thumbnail-image-url: https://capitalq.com.au/wp-content/uploads/2019/11/Naval-Podcast-2-768x768.jpg
f_image-url: https://capitalq.com.au/wp-content/uploads/2019/11/Naval-Podcast-2-768x768.jpg
f_text: Even the most powerful computers can’t answer ‘why?’
f_reading-time: "6"
f_title: More Compute Power Doesn’t Produce Artificial General Intelligence
f_source: https://nav.al/agi
f_author-4: cms/team/bence.md
f_category-5: cms/categories/ai-ml.md
f_tags:
  - cms/tags/machine-learning.md
  - cms/tags/interviews.md
f_social-media-share-image:
  url: https://uploads-ssl.webflow.com/62065e264f3132155f575139/62065e264f31324eea575270_external-content.duckduckgo.jpg
  alt: null
f_featured: true
layout: "[posts].html"
slug: more-compute-power-doesnt-produce-artificial-general-intelligence
f_trending: false
tags: posts
---

Great fan of Naval. It's recommended to listen at least three episodes of his podcast (each of them are between one and two minutes long) to understand where he is coming from.

He brings up GPT-3 as an example, highlighting the fact that in the end a human will select the best items generated by a machine. Same stands for visual design: the designer picks the best looking assets, layouts and images from a pool of generated pieces.

Start listening from [**"Humans are Exceptional"**](https://nav.al/exceptional) – 22 October 2021, then continue with [**"More Compute Power Doesn’t Produce AGI**](https://nav.al/agi)**"** and finish with ["**It’s Mind Blowing That Our Minds Can’t Be Blown**](https://nav.al/mind-blowing)**"** (this episode itself brings up another fantastic thought)

All episodes are here:  [podcasts.apple.com](https://podcasts.apple.com/us/podcast/naval/id1454097755)

> "People talk a lot about [GPT-3](https://en.wikipedia.org/wiki/GPT-3), the text matching engine that [OpenAI](https://openai.com/) put out, which is a very impressive piece of software. They say, “Hey, I can use GPT-3 to generate great tweets.” That’s because, first, as a human you’re selecting the good tweets out of all the garbage that it generates. Second, it’s using some combination of plagiarism and synonym matching and so on to come up with plausible sounding stuff.

> The easiest way to see that what it’s generating doesn’t actually make any sense is to ask it a follow-up question. Take a GPT-3 generated output and ask it, “Why is that the case?” Or make a prediction based on that and watch it completely fall apart because there’s no underlying explanation.

> It’s parroting. It’s brilliant Bayesian reasoning. It’s extrapolating from what it already sees out there generated by humans on the web, but it doesn’t have an underlying model of reality that can explain the seen in terms of the unseen. And I think that’s critical.

> That is what humans do uniquely that no other creature, no other computer, no other intelligence—biological or artificial—that we have ever encountered does."
